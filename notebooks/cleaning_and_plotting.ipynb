{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopy\n",
    "import folium\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/Seb/development/redi/data-analysis-project/data/fatalencounters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smaller_df = df.drop([\n",
    "    'Timestamp', 'URL of image of deceased',\n",
    "    '20791', 'Date&Description',\n",
    "    'State Data Status Prior to Jan. 1, 2013. All states complete after Jan. 1, 2013',\n",
    "    'Link to news article or photo of official document',\n",
    "    'Official disposition of death (justified or other)',\n",
    "    'A brief description of the circumstances surrounding the death',\n",
    "    'Unique identifier/submitted by'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to plot locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = smaller_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_colnames = [column_name for column_name in smaller_df.columns.tolist()\n",
    "                     if column_name.startswith('Location')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with NaNs in location columns. \n",
    "clean_locations_df = smaller_df.dropna(axis=0, subset=location_colnames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(test_row[location_colnames].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_location_details(row, location_keys=location_colnames):\n",
    "    \"\"\"Custom function to combine all location data from each individual location column.\"\"\"\n",
    "    return ', '.join(row[location_keys].values.tolist())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new column with all location data\n",
    "clean_locations_df['full_address'] = clean_locations_df.apply(combine_location_details, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Geocoding with G maps\n",
    "#def geocode(row):\n",
    " #   response = gmaps.geocode(row['full_address'])\n",
    " #   lat = response['geometry']['location']['latitude']\n",
    "#    lon = response['geometry']['location']['longitude']\n",
    "  #  return response[0]['geometry']['location']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_1000_cordinates = pd.read_csv(\n",
    "    '/Users/Seb/development/redi/data-analysis-project/notebooks/first_1000_coordinates.csv',\n",
    "    header=None, names=['index', 'coordinates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to geocode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "coordinates = []\n",
    "for index, row in clean_locations_df.head(1000).iterrows():\n",
    "    try:\n",
    "        print(index)\n",
    "        coord = geocode(row)\n",
    "        coordinates.append(coord)\n",
    "    except:\n",
    "        print(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(coordinates).to_csv('first_1000_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_1.save('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyA1HN0Rh5IomezuBbNIOYiE8J8q16HBriE')\n",
    "\n",
    "# Geocoding an address\n",
    "geocode_result = gmaps.geocode('1600 Amphitheatre Parkway, Mountain View, CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_result[0]['geometry']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "addresses = []\n",
    "for row, values in clean_locations_df.head(100).iterrows():\n",
    "    try:\n",
    "        addresses.append(combine_location_details(values))\n",
    "    except TypeError as err:\n",
    "        print(err)\n",
    "        print(row)\n",
    "        print(values[location_colnames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing first_1000_coordiantes df\n",
    "first_1000_cordinates['lat'] =  first_1000_cordinates['coordinates'].apply(lambda row: eval(row)['lat'])\n",
    "first_1000_cordinates['lng'] =  first_1000_cordinates['coordinates'].apply(lambda row: eval(row)['lng'])\n",
    "first_1000_cordinates = first_1000_cordinates.drop(['index', 'coordinates'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Cause of death to dateframe\n",
    "first_1000_cordinates['cause_of_death'] = clean_locations_df.head(1000)['Cause of death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Preparring for making colormap\n",
    "causes_list = pd.Series(clean_locations_df.head(1000)['Cause of death'].unique().tolist())\n",
    "# Simplifying list for now\n",
    "causes_list = causes_list.tolist()[:-5]\n",
    "colors = ['Brown', 'Red', 'Green', 'Orange', 'Black', 'Pink', 'Yellow', 'Blue']\n",
    "# Mapping colors and causes of death\n",
    "causes_colormap = {key: value for key, value in zip(causes_list, colors)}\n",
    "#Creatign default dict as we simplified the list.\n",
    "causes_colormap = defaultdict(lambda:'#2EFE2E', causes_colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating base map\n",
    "center_x = first_1000_cordinates['lng'].mean()\n",
    "center_y = first_1000_cordinates['lat'].mean()\n",
    "map_1 = folium.Map(location=[center_y, center_x], zoom_start=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Assigning circles to bsae map\n",
    "for index, row in first_1000_cordinates.head(1000).iterrows():\n",
    "    color = causes_colormap[row['cause_of_death']]\n",
    "    folium.CircleMarker([row['lat'], row['lng']],\n",
    "                        color='black', fill_color=color,\n",
    "                        radius=5, fill_opacity=1).add_to(map_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1.save('first_1000.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(causes_colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_locations_df.head(1000)['Subject\\'s gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the first 1000 rows with Cause of Death as a color. Clearly, gunshots kill more people.\n",
    "We would like to plot the Subject's race but there is a lot of unspecified data. We could work this by trying to \n",
    "plot the number of unspecified over time and saying how it changes.\n",
    "We should look at Subject's gender and age\n",
    "\n",
    "What we really should do is look at demographic, crime data, and police training data. Plot crime rate for each state, police training success for each state etc. General demographics would be interesting. See how they relate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
